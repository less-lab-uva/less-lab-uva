---
title: Testing Neural Networks with Generative Models
image: /images/projects/TNNMNIST.pdf, /images/projects/TNNDiagram.pdf, 
date: 2015-01-20
team: Swaroopa Dola, Mary Lou Soffa, and Matthew B. Dwyer 
label: DNN
---

<a name="tnn"></a>

Abstract: Our research involves developing techniques for testing DNNs using inputs that follow the training distribution of the DNN under test. Generative models can learn the distribution of the dataset they are trained on. This feature of the generative models is used for classifying test inputs as valid or invalid. The input classifier used in our study is a variational autoencoder (VAE) based algorithm that outputs the reconstruction probability of the input. Fig. 1 shows samples classified as either valid or invalid by the VAE based classifier for MNISTdataset. The test generation technique is shown in Fig. 2 where 𝑀𝑥 is the VAE based input classifier. The test input generated by the test generator 𝐺𝑇 is passed through the input classifier which outputs the reconstruction probability of the input with respect to the input distribution estimated by the VAE. This probability can guide the 𝐺𝑇 in generating valid test inputs. We conducted a study to evaluate the test generation technique using DeepXplore as the baseline test generator for 8 DNN networks. The results indicate that the technique significantly increases the generation of valid test inputs and reduces the time to generate valid tests when compared to the baseline.
Pictures:


Figure 1. Valid(top row) and invalid (bottom row) test inputs classified by the VAE for MNIST dataset
Figure 2. Test generation using a generative mod
